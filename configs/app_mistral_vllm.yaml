model:
  backend: vllm
  name: mistralai/Mistral-7B-Instruct-v0.2
  max_new_tokens: 512
  temperature: 0.2
  top_p: 0.9
ingest:
  max_pages_per_pdf: 2000
  min_chunk_chars: 400
  max_chunk_chars: 2200
  heading_regex: '^\s*(\d+(?:\.\d+){1,6})\s+(.+?)\s*$'

retrieval:
  bm25_topk: 80
  dense_topk: 80
  fused_topk: 60
  rerank_topk: 12

  rrf_k: 60
  rrf_w_bm25: 1.0
  rrf_w_dense: 1.0
  rrf_cap_bm25: 80
  rrf_cap_dense: 80

  enable_dense: true
  enable_rerank: true

  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2

  reranker_batch_size: 64
  reranker_device: cuda
  reranker_max_length: 512

packing:
  max_context_chars: 25000
  neighbor_window: 1
  include_headings: true

gate:
  min_rerank_score: -1.25
  enable_query_rewrite: false
  max_rounds: 1

paths:
  raw_specs_dir: data/raw_specs
  chunks_path: data/intermediate/chunks.jsonl
  docstore_path: data/indexes/docstore.sqlite
  bm25_dir: data/indexes/bm25
  faiss_dir: data/indexes/faiss

server:
  host: 0.0.0.0
  port: 8000
