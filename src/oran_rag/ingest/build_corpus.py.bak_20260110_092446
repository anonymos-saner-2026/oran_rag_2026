from __future__ import annotations
import argparse
import os
import sqlite3
from pathlib import Path
from typing import Any, Dict, List

from ..utils import load_yaml, save_jsonl, guess_wg_from_filename, guess_version_from_filename
from ..utils import is_definition_section, is_normative_text
from .pdf_to_sections import extract_pdf_text, split_into_lines, compile_heading_regex, detect_headings
from .chunker import build_chunks_from_lines

def ensure_docstore(db_path: str) -> None:
    Path(db_path).parent.mkdir(parents=True, exist_ok=True)
    con = sqlite3.connect(db_path)
    cur = con.cursor()
    cur.execute(
        '''
        CREATE TABLE IF NOT EXISTS chunks (
            chunk_id TEXT PRIMARY KEY,
            doc_id TEXT,
            version TEXT,
            wg TEXT,
            clause_id TEXT,
            section_path TEXT,
            title TEXT,
            text TEXT,
            page_start INTEGER,
            page_end INTEGER,
            is_definition INTEGER,
            is_normative INTEGER
        );
        '''
    )
    cur.execute("CREATE INDEX IF NOT EXISTS idx_chunks_doc ON chunks(doc_id);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_chunks_wg ON chunks(wg);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_chunks_clause ON chunks(clause_id);")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_chunks_section ON chunks(section_path);")
    con.commit()
    con.close()

def upsert_chunks(db_path: str, rows: List[Dict[str, Any]]) -> None:
    con = sqlite3.connect(db_path)
    cur = con.cursor()
    cur.executemany(
        '''
        INSERT OR REPLACE INTO chunks
        (chunk_id, doc_id, version, wg, clause_id, section_path, title, text, page_start, page_end, is_definition, is_normative)
        VALUES
        (:chunk_id, :doc_id, :version, :wg, :clause_id, :section_path, :title, :text, :page_start, :page_end, :is_definition, :is_normative)
        ''',
        rows,
    )
    con.commit()
    con.close()

def build_for_pdf(pdf_path: str, cfg: Dict[str, Any]) -> List[Dict[str, Any]]:
    ingest_cfg = cfg["ingest"]
    max_pages = ingest_cfg.get("max_pages_per_pdf", None)
    pages = extract_pdf_text(pdf_path, max_pages=max_pages)

    lines = split_into_lines(pages)
    heading_re = compile_heading_regex(ingest_cfg["heading_regex"])
    headings = detect_headings(lines, heading_re)

    file_name = os.path.basename(pdf_path)
    doc_id = os.path.splitext(file_name)[0]
    wg = guess_wg_from_filename(file_name)
    version = guess_version_from_filename(file_name)

    chunks = build_chunks_from_lines(
        doc_id=doc_id,
        version=version,
        wg=wg,
        lines=lines,
        headings=headings,
        min_chars=int(ingest_cfg["min_chunk_chars"]),
        max_chars=int(ingest_cfg["max_chunk_chars"]),
        is_definition_fn=is_definition_section,
        is_normative_fn=is_normative_text,
    )

    out: List[Dict[str, Any]] = []
    for c in chunks:
        out.append(
            {
                "chunk_id": c.chunk_id,
                "doc_id": c.doc_id,
                "version": c.version,
                "wg": c.wg,
                "clause_id": c.clause_id,
                "section_path": c.section_path,
                "title": c.title,
                "text": c.text,
                "page_start": c.page_start,
                "page_end": c.page_end,
                "is_definition": int(c.is_definition),
                "is_normative": int(c.is_normative),
            }
        )
    return out

def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", type=str, required=True)
    args = ap.parse_args()

    cfg = load_yaml(args.config)
    raw_dir = cfg["paths"]["raw_specs_dir"]
    chunks_path = cfg["paths"]["chunks_path"]
    docstore_path = cfg["paths"]["docstore_path"]

    ensure_docstore(docstore_path)

    pdfs = sorted(str(p) for p in Path(raw_dir).glob("*.pdf"))
    if not pdfs:
        raise SystemExit(f"[ERROR] No PDFs found in {raw_dir}")

    all_rows: List[Dict[str, Any]] = []
    for pdf in pdfs:
        rows = build_for_pdf(pdf, cfg)
        all_rows.extend(rows)
        print(f"[OK] {os.path.basename(pdf)} -> {len(rows)} chunks")

    save_jsonl(chunks_path, all_rows)
    upsert_chunks(docstore_path, all_rows)
    print(f"[DONE] chunks.jsonl: {chunks_path}")
    print(f"[DONE] docstore.sqlite: {docstore_path}")

if __name__ == "__main__":
    main()
